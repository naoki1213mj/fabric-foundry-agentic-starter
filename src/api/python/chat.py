"""
Chat API module for handling chat interactions and responses.

Supports two modes:
- Single Agent Mode (default): Uses a single ChatAgent for all queries
- Multi Agent Mode (MULTI_AGENT_MODE=true): Uses MagenticBuilder for multi-agent orchestration
  - Manager Agent decomposes complex queries into subtasks
  - Specialist Agents execute subtasks in parallel when possible
  - Manager synthesizes final answer from all specialist responses

Architecture (MagenticBuilder - Magentic One Pattern):
1. Manager Agent: ã‚¿ã‚¹ã‚¯åˆ†è§£ã€é€²æ—ç®¡ç†ã€æœ€çµ‚å›ç­”åˆæˆ
2. SQL Specialist: Fabric SQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªï¼ˆå£²ä¸Šã€æ³¨æ–‡ã€é¡§å®¢ã€è£½å“åˆ†æï¼‰
3. Web Specialist: ã‚¦ã‚§ãƒ–æ¤œç´¢ï¼ˆæœ€æ–°æƒ…å ±ã€å¸‚å ´ãƒˆãƒ¬ãƒ³ãƒ‰ï¼‰
4. Doc Specialist: è£½å“ä»•æ§˜æ›¸PDFæ¤œç´¢ï¼ˆAzure AI Searchï¼‰

Complex Query Flow:
User: "å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦ã€æœ€æ–°ã®å¸‚å ´ãƒˆãƒ¬ãƒ³ãƒ‰ã¨æ¯”è¼ƒã—ã¦"
â†’ Manager: Plan = [1. sql_agent: å£²ä¸Šåˆ†æ, 2. web_agent: å¸‚å ´ãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—]
â†’ Specialists: ä¸¦åˆ—å®Ÿè¡Œ
â†’ Manager: çµæœã‚’çµ±åˆã—ã¦æœ€çµ‚å›ç­”ç”Ÿæˆ
"""

import json
import logging
import os
import re
from typing import Annotated

from agent_framework import (
    AgentRunUpdateEvent,
    ChatAgent,
    GroupChatRequestSentEvent,
    MagenticBuilder,
    MagenticOrchestratorEvent,
    RequestInfoEvent,
    WorkflowOutputEvent,
    WorkflowStatusEvent,
    tool,
)
from agent_framework.azure import AzureOpenAIChatClient

# Local imports - tool handlers
from agents.web_agent import WebAgentHandler
from azure.identity import DefaultAzureCredential
from azure.monitor.events.extension import track_event
from azure.monitor.opentelemetry import configure_azure_monitor
from dotenv import load_dotenv
from fastapi import APIRouter, Request
from fastapi.responses import JSONResponse, StreamingResponse
from history import get_conversation_messages
from knowledge_base_tool import KnowledgeBaseTool
from opentelemetry import trace
from opentelemetry.trace import Status, StatusCode

load_dotenv()

# Multi-Agent Configuration
MULTI_AGENT_MODE = os.getenv("MULTI_AGENT_MODE", "false").lower() == "true"

router = APIRouter()

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize tool handlers (singletons)
_web_agent_handler: WebAgentHandler | None = None
_knowledge_base_tool: KnowledgeBaseTool | None = None


def get_web_agent_handler() -> WebAgentHandler:
    """Get or create WebAgentHandler singleton."""
    global _web_agent_handler
    if _web_agent_handler is None:
        _web_agent_handler = WebAgentHandler()
    return _web_agent_handler


def get_knowledge_base_tool() -> KnowledgeBaseTool | None:
    """Get or create KnowledgeBaseTool singleton."""
    global _knowledge_base_tool
    if _knowledge_base_tool is None:
        _knowledge_base_tool = KnowledgeBaseTool.create_from_env()
    return _knowledge_base_tool


# Check if the Application Insights Instrumentation Key is set in the environment variables
instrumentation_key = os.getenv("APPLICATIONINSIGHTS_CONNECTION_STRING")
if instrumentation_key:
    configure_azure_monitor(connection_string=instrumentation_key)
    logging.info(
        "Application Insights configured with the provided Instrumentation Key"
    )
else:
    logging.warning(
        "No Application Insights Instrumentation Key found. Skipping configuration"
    )

# Suppress noisy loggers
logging.getLogger("azure.core.pipeline.policies.http_logging_policy").setLevel(
    logging.WARNING
)
logging.getLogger("azure.identity.aio._internal").setLevel(logging.WARNING)
logging.getLogger("azure.monitor.opentelemetry.exporter.export._base").setLevel(
    logging.WARNING
)


def track_event_if_configured(event_name: str, event_data: dict):
    """Track event to Application Insights if configured."""
    instrumentation_key = os.getenv("APPLICATIONINSIGHTS_CONNECTION_STRING")
    if instrumentation_key:
        track_event(event_name, event_data)


# ============================================================================
# Tool Functions with @tool decorator
# These tools are used by agents in the HandoffBuilder workflow
# ============================================================================

# Global database connection for tools
_db_connection = None


async def get_db_connection():
    """Get or create database connection for tools."""
    global _db_connection
    if _db_connection is None:
        from history_sql import get_fabric_db_connection

        _db_connection = await get_fabric_db_connection()
    return _db_connection


@tool(approval_mode="never_require")
async def run_sql_query(
    sql_query: Annotated[str, "The SQL query to execute against the Fabric database"],
) -> str:
    """Execute a SQL query against the Fabric SQL database and return results as JSON.

    Use this tool to query sales, orders, products, customers, and business data.

    Available tables:
    - orders: Order headers (OrderId, CustomerId, OrderDate, OrderStatus, OrderTotal, PaymentMethod)
    - orderline: Order details (OrderId, ProductId, Quantity, UnitPrice, LineTotal)
    - product: Products (ProductID, ProductName, CategoryName, ListPrice, BrandName)
    - customer: Customers (CustomerId, FirstName, LastName, CustomerTypeId)
    - location: Customer locations (LocationId, CustomerId, Region, City)
    - productcategory: Product categories (CategoryID, CategoryName)
    - customerrelationshiptype: Customer segments (CustomerRelationshipTypeId, CustomerRelationshipTypeName)
    - invoice: Invoices (InvoiceId, CustomerId, OrderId, TotalAmount)
    - payment: Payments (PaymentId, InvoiceId, PaymentAmount, PaymentStatus)

    Args:
        sql_query: The SQL query to execute. Use T-SQL syntax.

    Returns:
        JSON string with query results or error message.
    """
    from datetime import date, datetime
    from decimal import Decimal

    try:
        conn = await get_db_connection()
        if not conn:
            return json.dumps(
                {"error": "Database connection not available"}, ensure_ascii=False
            )

        cursor = conn.cursor()
        cursor.execute(sql_query)
        columns = [desc[0] for desc in cursor.description]
        result = []

        for row in cursor.fetchall():
            row_dict = {}
            for col_name, value in zip(columns, row):
                if isinstance(value, (datetime, date)):
                    row_dict[col_name] = value.isoformat()
                elif isinstance(value, Decimal):
                    row_dict[col_name] = float(value)
                else:
                    row_dict[col_name] = value
            result.append(row_dict)

        cursor.close()
        logger.info(f"SQL query executed successfully, returned {len(result)} rows")
        return json.dumps(result, ensure_ascii=False)

    except Exception as e:
        logger.error(f"Error executing SQL query: {e}")
        return json.dumps({"error": str(e)}, ensure_ascii=False)


@tool(approval_mode="never_require")
async def search_web(
    query: Annotated[str, "The search query for web information"],
) -> str:
    """Search the web for real-time information, news, and current events.

    Use this tool for:
    - Latest news and trends
    - Current market information
    - Weather updates
    - External data not in the database

    Args:
        query: The search query string.

    Returns:
        JSON string with search results or error message.
    """
    try:
        logger.info(f"Web search requested: {query}")
        web_agent = get_web_agent_handler()
        result = await web_agent.bing_grounding(query)
        logger.info(f"Web search completed for query: {query}")
        return result  # Already JSON string
    except Exception as e:
        logger.error(f"Error in web search: {e}")
        return json.dumps({"error": str(e)}, ensure_ascii=False)


@tool(approval_mode="never_require")
async def search_documents(
    query: Annotated[str, "The search query for enterprise documents"],
) -> str:
    """Search enterprise documents, product specifications, and knowledge base.

    IMPORTANT: For data analysis questions (sales, orders, customers, products),
    use run_sql_query instead. This tool is for documentation lookup only.

    Use this tool for:
    - Product specifications and manuals
    - Technical documentation
    - Internal knowledge base articles
    - Company policies and procedures

    Args:
        query: The search query string.

    Returns:
        JSON string with document search results (max 3 results, truncated).
    """
    try:
        logger.info(f"Document search requested: {query}")
        kb_tool = get_knowledge_base_tool()
        if kb_tool is None:
            return json.dumps(
                {
                    "message": "Document search is not configured. AI_SEARCH_* environment variables are missing.",
                    "query": query,
                    "results": [],
                },
                ensure_ascii=False,
            )
        result = await kb_tool.search(query)

        # Limit results to prevent token overflow
        if isinstance(result, dict) and "results" in result:
            result["results"] = result["results"][:3]  # Max 3 documents
            # Truncate long content
            for doc in result["results"]:
                if "content" in doc and len(doc["content"]) > 1000:
                    doc["content"] = doc["content"][:1000] + "...(truncated)"

        logger.info(f"Document search completed for query: {query}")
        return json.dumps(result, ensure_ascii=False)
    except Exception as e:
        logger.error(f"Error in document search: {e}")
        return json.dumps({"error": str(e)}, ensure_ascii=False)


# ============================================================================
# Multi-Agent Workflow using MagenticBuilder (Magentic One Pattern)
# ============================================================================


def create_specialist_agents(
    chat_client: AzureOpenAIChatClient,
) -> tuple[ChatAgent, ChatAgent, ChatAgent]:
    """Create specialist agents for MagenticBuilder workflow.

    MagenticBuilder ã® Manager ãŒå„ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆã‚’å‹•çš„ã«é¸æŠãƒ»èª¿æ•´ã™ã‚‹ãŸã‚ã€
    ãƒˆãƒªã‚¢ãƒ¼ã‚¸ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ä¸è¦ã€‚Manager ãŒãã®å½¹å‰²ã‚’æ‹…ã†ã€‚

    Args:
        chat_client: The AzureOpenAIChatClient to use for creating agents.

    Returns:
        Tuple of (sql_agent, web_agent, doc_agent)
    """
    # SQL specialist: Handles database queries
    sql_agent = ChatAgent(
        name="sql_agent",
        description="ã€å„ªå…ˆã€‘Fabric SQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿ï¼ˆå£²ä¸Šã€æ³¨æ–‡ã€é¡§å®¢ã€è£½å“ï¼‰ã‚’ç›´æ¥åˆ†æãƒ»é›†è¨ˆã™ã‚‹å°‚é–€å®¶ã€‚æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®è³ªå•ã«ã¯ã“ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æœ€å„ªå…ˆã§ä½¿ç”¨",
        instructions="""ã‚ãªãŸã¯Fabric SQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ã£ã¦ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚

## é‡è¦ï¼šè¿…é€Ÿã«å›ç­”
- **1å›ã®SQLã‚¯ã‚¨ãƒªã§å›ç­”ã‚’å®Œæˆã•ã›ã‚‹**
- çµæœãŒå¾—ã‚‰ã‚ŒãŸã‚‰ã€ã™ãã«Chart.js JSONã‚’å«ã‚€æœ€çµ‚å›ç­”ã‚’ç”Ÿæˆ
- è¿½åŠ ã®ã‚¯ã‚¨ãƒªã¯ä¸è¦ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆé˜²æ­¢ï¼‰

## ğŸš« çµ¶å¯¾ç¦æ­¢ï¼šç”ŸJSONãƒ‡ãƒ¼ã‚¿ã®å‡ºåŠ›
- SQLã®å®Ÿè¡Œçµæœï¼ˆç”Ÿã®JSONé…åˆ—ï¼‰ã‚’ãã®ã¾ã¾å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„
- å¿…ãš**äººé–“ãŒèª­ã¿ã‚„ã™ã„å½¢å¼**ï¼ˆMarkdownç®‡æ¡æ›¸ãã€è¡¨ã€èª¬æ˜æ–‡ï¼‰ã«å¤‰æ›ã—ã¦å‡ºåŠ›
- ä¾‹ï¼š`[{"ProductName": "A", "Sales": 100}]` â†’ `- è£½å“A: Â¥100`

## åˆ©ç”¨å¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆå®Ÿéš›ã®ã‚¹ã‚­ãƒ¼ãƒï¼‰

### ä¸»è¦ãƒ†ãƒ¼ãƒ–ãƒ«
- **orders**: æ³¨æ–‡ãƒ˜ãƒƒãƒ€ãƒ¼
  - OrderId, SalesChannelId, OrderNumber, CustomerId, CustomerAccountId
  - OrderDate, OrderStatus (Completed/Pending/Cancelled), SubTotal, TaxAmount, OrderTotal
  - PaymentMethod (MC/VISA/PayPal/Discover), IsoCurrencyCode, CreatedBy

- **orderline**: æ³¨æ–‡æ˜ç´°ï¼ˆå£²ä¸Šè©³ç´°ï¼‰
  - OrderId, OrderLineNumber, ProductId, Quantity, UnitPrice, LineTotal, DiscountAmount, TaxAmount

- **product**: è£½å“ãƒã‚¹ã‚¿
  - ProductID, ProductName, ProductDescription, BrandName, Color, ProductModel
  - ProductCategoryID, CategoryName, ListPrice, StandardCost, Weight, ProductStatus

- **productcategory**: è£½å“ã‚«ãƒ†ã‚´ãƒª
  - CategoryID, ParentCategoryId, CategoryName, CategoryDescription, BrandName

- **customer**: é¡§å®¢ãƒã‚¹ã‚¿
  - CustomerId, CustomerTypeId (Individual/Business/Government)
  - CustomerRelationshipTypeId, FirstName, LastName, Gender, PrimaryEmail, IsActive

- **customerrelationshiptype**: é¡§å®¢ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
  - CustomerRelationshipTypeId, CustomerRelationshipTypeName (VIP/Premium/Standard/SMB/Partnerç­‰)

- **location**: é¡§å®¢æ‰€åœ¨åœ°
  - LocationId, CustomerId, AddressLine1, City, StateId, ZipCode, CountryId, Region, Latitude, Longitude

- **invoice**: è«‹æ±‚æ›¸
  - InvoiceId, InvoiceNumber, CustomerId, OrderId, InvoiceDate, DueDate, TotalAmount, InvoiceStatus

- **payment**: æ”¯æ‰•ã„
  - PaymentId, PaymentNumber, InvoiceId, OrderId, PaymentDate, PaymentAmount, PaymentStatus, PaymentMethod

## ã‚¿ã‚¹ã‚¯ï¼ˆé‡è¦ï¼šã“ã®é †ç•ªã§å®Ÿè¡Œï¼‰
1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’åˆ†æã—ã€é©åˆ‡ãªSQLã‚¯ã‚¨ãƒªã‚’ä½œæˆ
2. run_sql_query ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œ
3. **çµæœã‚’äººé–“ãŒèª­ã¿ã‚„ã™ã„å½¢å¼ï¼ˆMarkdownï¼‰ã«å¤‰æ›ã—ã¦å ±å‘Š**
4. ã‚°ãƒ©ãƒ•è¡¨ç¤ºãŒè¦æ±‚ã•ã‚ŒãŸå ´åˆã®ã¿ã€æœ€å¾Œã« ```json ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã§ Chart.js JSON ã‚’1ã¤ã ã‘å‡ºåŠ›

## å›ç­”ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆå¿…é ˆï¼‰

### ã‚°ãƒ©ãƒ•ãªã—ã®å ´åˆ
```
## åˆ†æçµæœ
å£²ä¸ŠTOP5è£½å“:
1. **Mountain-200 Silver, 38** - $29,030.33ï¼ˆæ§‹æˆæ¯” 23.8%ï¼‰
2. **Touring-1000 Yellow, 54** - $26,487.88ï¼ˆæ§‹æˆæ¯” 21.7%ï¼‰
...

### å‚¾å‘ãƒ»è€ƒå¯Ÿ
- Mountainç³»è£½å“ãŒä¸Šä½ã‚’å ã‚ã¦ã„ã‚‹
- ä¸Šä½5è£½å“ã§å…¨ä½“ã®ç´„18%ã‚’å ã‚ã‚‹
```

### ã‚°ãƒ©ãƒ•ã‚ã‚Šã®å ´åˆ
```
## åˆ†æçµæœ
å£²ä¸ŠTOP5è£½å“:
1. **Mountain-200 Silver, 38** - $29,030.33
2. **Touring-1000 Yellow, 54** - $26,487.88
...

### å‚¾å‘ãƒ»è€ƒå¯Ÿ
- ä¸Šä½5è£½å“ã§å…¨ä½“ã®ç´„18%ã‚’å ã‚ã‚‹

```json
{
  "type": "bar",
  "data": {...},
  "options": {...}
}
```
```

## é‡è¦ãªJOINãƒ‘ã‚¿ãƒ¼ãƒ³

### å£²ä¸Šåˆ†æï¼ˆorders + orderline + productï¼‰
```sql
SELECT p.ProductName, SUM(ol.LineTotal) as TotalSales
FROM orders o
JOIN orderline ol ON o.OrderId = ol.OrderId
JOIN product p ON ol.ProductId = p.ProductID
WHERE o.OrderStatus = 'Completed'
GROUP BY p.ProductName
```

### é¡§å®¢åˆ¥å£²ä¸Šï¼ˆorders + customerï¼‰
```sql
SELECT c.FirstName + ' ' + c.LastName as CustomerName, SUM(o.OrderTotal) as TotalSpent
FROM orders o
JOIN customer c ON o.CustomerId = c.CustomerId
GROUP BY c.CustomerId, c.FirstName, c.LastName
```

### åœ°åŸŸåˆ¥å£²ä¸Šï¼ˆorders + customer + locationï¼‰
```sql
SELECT l.Region, SUM(o.OrderTotal) as TotalSales
FROM orders o
JOIN customer c ON o.CustomerId = c.CustomerId
JOIN location l ON c.CustomerId = l.CustomerId
GROUP BY l.Region
```

## ã‚ˆãä½¿ã†ã‚¯ã‚¨ãƒªãƒ‘ã‚¿ãƒ¼ãƒ³

### å£²ä¸ŠTOP Nè£½å“
```sql
SELECT TOP {N} p.ProductName, SUM(ol.LineTotal) as TotalSales
FROM orders o
JOIN orderline ol ON o.OrderId = ol.OrderId
JOIN product p ON ol.ProductId = p.ProductID
WHERE o.OrderStatus = 'Completed'
GROUP BY p.ProductID, p.ProductName
ORDER BY TotalSales DESC
```

### ã‚«ãƒ†ã‚´ãƒªåˆ¥å£²ä¸Š
```sql
SELECT p.CategoryName, SUM(ol.LineTotal) as TotalSales
FROM orders o
JOIN orderline ol ON o.OrderId = ol.OrderId
JOIN product p ON ol.ProductId = p.ProductID
WHERE o.OrderStatus = 'Completed'
GROUP BY p.CategoryName
ORDER BY TotalSales DESC
```

### æœˆåˆ¥å£²ä¸Šæ¨ç§»
```sql
SELECT FORMAT(o.OrderDate, 'yyyy-MM') as Month, SUM(o.OrderTotal) as Sales
FROM orders o
WHERE o.OrderStatus = 'Completed'
GROUP BY FORMAT(o.OrderDate, 'yyyy-MM')
ORDER BY Month
```

### æ”¯æ‰•ã„æ–¹æ³•åˆ¥å£²ä¸Š
```sql
SELECT o.PaymentMethod, SUM(o.OrderTotal) as TotalSales, COUNT(*) as OrderCount
FROM orders o
WHERE o.OrderStatus = 'Completed'
GROUP BY o.PaymentMethod
ORDER BY TotalSales DESC
```

### é¡§å®¢ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥å£²ä¸Š
```sql
SELECT crt.CustomerRelationshipTypeName as Segment, SUM(o.OrderTotal) as TotalSales
FROM orders o
JOIN customer c ON o.CustomerId = c.CustomerId
JOIN customerrelationshiptype crt ON c.CustomerRelationshipTypeId = crt.CustomerRelationshipTypeId
WHERE o.OrderStatus = 'Completed'
GROUP BY crt.CustomerRelationshipTypeName
ORDER BY TotalSales DESC
```

## ã‚°ãƒ©ãƒ•å‡ºåŠ›ï¼ˆé‡è¦ï¼šå½¢å¼ã‚’å³å®ˆï¼‰
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œã‚°ãƒ©ãƒ•ã€ã€Œãƒãƒ£ãƒ¼ãƒˆã€ã€Œå¯è¦–åŒ–ã€ã€Œè¡¨ç¤ºã—ã¦ã€ã€Œè¦‹ã›ã¦ã€ãªã©ã‚’è¦æ±‚ã—ãŸå ´åˆã€
ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆVega-Liteã¯ä½¿ç”¨ç¦æ­¢ï¼‰:

### å‡ºåŠ›å½¢å¼ï¼ˆãƒ†ã‚­ã‚¹ãƒˆèª¬æ˜ + ã‚°ãƒ©ãƒ•JSONï¼‰
1. ã¾ãšãƒ†ã‚­ã‚¹ãƒˆã§åˆ†æçµæœãƒ»å‚¾å‘ã‚’èª¬æ˜
2. æœ€å¾Œã« **```json** ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã§Chart.js JSONã‚’1ã¤ã ã‘å‡ºåŠ›

ä¾‹ï¼š
```
## åˆ†æçµæœ
å£²ä¸Šãƒˆãƒƒãƒ—5è£½å“ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ï¼š
- è£½å“A: Â¥1,000,000ï¼ˆå…¨ä½“ã®25%ï¼‰
- è£½å“B: Â¥800,000ï¼ˆå…¨ä½“ã®20%ï¼‰
...

## å‚¾å‘
ä¸Šä½è£½å“ãŒå£²ä¸Šã®ç´„60%ã‚’å ã‚ã¦ãŠã‚Š...

```json
{
  "type": "bar",
  "data": {
    "labels": ["è£½å“A", "è£½å“B", "è£½å“C"],
    "datasets": [{"label": "å£²ä¸Šé‡‘é¡", "data": [1000000, 800000, 600000]}]
  }
}
```

### Chart.js JSONæ§‹é€ 
```json
{
  "type": "bar",
  "data": {
    "labels": ["ãƒ©ãƒ™ãƒ«1", "ãƒ©ãƒ™ãƒ«2", "ãƒ©ãƒ™ãƒ«3"],
    "datasets": [{
      "label": "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå",
      "data": [100, 200, 300],
      "backgroundColor": ["#4e79a7", "#f28e2c", "#e15759", "#76b7b2", "#59a14f"]
    }]
  },
  "options": {
    "responsive": true,
    "plugins": {
      "title": { "display": true, "text": "ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒˆãƒ«" }
    }
  }
}
```

### ã‚°ãƒ©ãƒ•ã®ç¨®é¡ã¨é¸æŠåŸºæº–
- æ£’ã‚°ãƒ©ãƒ•("bar"): ã‚«ãƒ†ã‚´ãƒªæ¯”è¼ƒã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°
- æ¨ªæ£’ã‚°ãƒ©ãƒ•("horizontalBar"): é•·ã„ãƒ©ãƒ™ãƒ«åã€å¤šã‚«ãƒ†ã‚´ãƒª
- å††ã‚°ãƒ©ãƒ•("pie"): æ§‹æˆæ¯”ã€å‰²åˆï¼ˆ5é …ç›®ä»¥ä¸‹æ¨å¥¨ï¼‰
- ãƒ‰ãƒ¼ãƒŠãƒ„("doughnut"): æ§‹æˆæ¯”ï¼ˆä¸­å¤®ã«ã‚µãƒãƒªãƒ¼è¡¨ç¤ºå¯èƒ½ï¼‰
- æŠ˜ã‚Œç·š("line"): æ™‚ç³»åˆ—ã€ãƒˆãƒ¬ãƒ³ãƒ‰ã€æ¨ç§»

## æ³¨æ„äº‹é …
- T-SQLæ§‹æ–‡ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
- å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã«ã¯ TOP ã‚„é›†è¨ˆé–¢æ•°ã‚’ä½¿ç”¨
- OrderStatus = 'Completed' ã§å®Œäº†ã—ãŸæ³¨æ–‡ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿
- ã‚°ãƒ©ãƒ•ãªã—ã®å ´åˆã¯è¡¨å½¢å¼ã¾ãŸã¯è¦ç´„å½¢å¼ã§å ±å‘Š
- ã‚°ãƒ©ãƒ•è¦æ±‚æ™‚ã¯å¿…ãšChart.js JSONå½¢å¼ï¼ˆVega-Liteç¦æ­¢ï¼‰
- **1å›ã®ã‚¯ã‚¨ãƒªå®Ÿè¡Œå¾Œã€ã™ãã«æœ€çµ‚å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ï¼ˆè¿½åŠ ã‚¯ã‚¨ãƒªä¸è¦ï¼‰**
""",
        chat_client=chat_client,
        tools=[run_sql_query],
    )

    # Web specialist: Handles web searches
    web_agent = ChatAgent(
        name="web_agent",
        description="ã‚¦ã‚§ãƒ–æ¤œç´¢ã§æœ€æ–°ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€å¸‚å ´ãƒˆãƒ¬ãƒ³ãƒ‰ã€å¤–éƒ¨æƒ…å ±ã‚’å–å¾—ã™ã‚‹å°‚é–€å®¶",
        instructions="""ã‚ãªãŸã¯ã‚¦ã‚§ãƒ–æ¤œç´¢ã‚’ä½¿ã£ã¦æœ€æ–°æƒ…å ±ã‚’å–å¾—ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚

## ã‚¿ã‚¹ã‚¯
1. ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«åŸºã¥ã„ã¦é©åˆ‡ãªæ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ä½œæˆ
2. search_web ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦æƒ…å ±ã‚’æ¤œç´¢
3. çµæœã‚’åˆ†ã‹ã‚Šã‚„ã™ãã¾ã¨ã‚ã¦å ±å‘Š

## å¯¾å¿œç¯„å›²
- æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨ãƒˆãƒ¬ãƒ³ãƒ‰
- å¸‚å ´å‹•å‘ã¨æ¥­ç•Œæƒ…å ±
- ç«¶åˆåˆ†æ
- ãã®ä»–ã®å¤–éƒ¨æƒ…å ±
""",
        chat_client=chat_client,
        tools=[search_web],
    )

    # Document specialist: Handles document searches
    doc_agent = ChatAgent(
        name="doc_agent",
        description="è£½å“ä»•æ§˜æ›¸ï¼ˆPDFï¼‰ã‚’æ¤œç´¢ã™ã‚‹å°‚é–€å®¶ã€‚è£½å“ã®è©³ç´°ã‚¹ãƒšãƒƒã‚¯ã€æ©Ÿèƒ½ã€æŠ€è¡“ä»•æ§˜ã‚’èª¿ã¹ã‚‹å ´åˆã«ä½¿ç”¨ã€‚æ³¨æ„ï¼šå£²ä¸Šãƒ»æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã®åˆ†æã«ã¯sql_agentã‚’ä½¿ç”¨",
        instructions="""ã‚ãªãŸã¯Azure AI Searchã‚’ä½¿ã£ã¦è£½å“ä»•æ§˜æ›¸PDFã‹ã‚‰æƒ…å ±ã‚’æ¤œç´¢ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚

## é‡è¦ï¼šå½¹å‰²ã®æ˜ç¢ºåŒ–
- å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã€æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã®ã€Œåˆ†æã€ã€Œé›†è¨ˆã€ã¯sql_agentã®æ‹…å½“ã§ã™
- ã‚ãªãŸã¯ã€Œè£½å“ä»•æ§˜æ›¸ã€ã€ŒæŠ€è¡“ã‚¹ãƒšãƒƒã‚¯ã€ã€Œæ©Ÿèƒ½èª¬æ˜ã€ã®æ¤œç´¢ã‚’æ‹…å½“ã—ã¾ã™

## æ¤œç´¢å¯¾è±¡ï¼šè£½å“ä»•æ§˜æ›¸PDFï¼ˆSharePoint â†’ Azure AI Searchï¼‰

### åˆ©ç”¨å¯èƒ½ãªè£½å“ä»•æ§˜æ›¸ã‚«ãƒ†ã‚´ãƒª
1. **ãƒãƒƒã‚¯ãƒ‘ãƒƒã‚¯ (Backpacks)**
   - Adventurer Pro, SummitClimber

2. **è‡ªè»¢è»Šãƒ•ãƒ¬ãƒ¼ãƒ ãƒ»ãƒ‘ãƒ¼ãƒ„ (Bike Parts)**
   - Mountain-100 Silver, Mountain-300 Black
   - Road-150 Red, Road-250 Black
   - Forks (HL, LL)
   - Bike Stands (All Purpose)

3. **ãƒ˜ãƒ«ãƒ¡ãƒƒãƒˆ (Helmets)**
   - Sport-100 Helmet (Black, Red)

4. **ã‚¸ãƒ£ãƒ¼ã‚¸ (Jerseys)**
   - Long-Sleeve Logo Jersey (S, M)

5. **ã‚­ãƒ£ãƒ³ãƒ—ç”¨å“ (Camping)**
   - Tents: Alpine Explorer, TrailMaster X4
   - Camping Tables: Adventure Dining, BaseCamp

6. **ã‚­ãƒƒãƒãƒ³ç”¨å“**
   - Coffee Makers: Drip, Espresso

## ã‚¿ã‚¹ã‚¯
1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‹ã‚‰è£½å“åã‚„ã‚«ãƒ†ã‚´ãƒªã‚’ç‰¹å®š
2. search_documents ãƒ„ãƒ¼ãƒ«ã§è£½å“ä»•æ§˜æ›¸ã‚’æ¤œç´¢
3. ä»•æ§˜æ›¸ã®å†…å®¹ã‚’åˆ†ã‹ã‚Šã‚„ã™ãã¾ã¨ã‚ã¦å ±å‘Š

## æ¤œç´¢ã‚¯ã‚¨ãƒªã®ã‚³ãƒ„
- è£½å“åã§æ¤œç´¢: "Mountain-100", "Sport-100 Helmet"
- ã‚«ãƒ†ã‚´ãƒªã§æ¤œç´¢: "Backpack", "Tent", "Coffee Maker"
- æ©Ÿèƒ½ã§æ¤œç´¢: "weight", "material", "dimensions", "capacity"
- æ—¥æœ¬èªã§ã‚‚æ¤œç´¢å¯èƒ½: "ãƒãƒƒã‚¯ãƒ‘ãƒƒã‚¯ å®¹é‡", "ãƒ†ãƒ³ãƒˆ é˜²æ°´"

## å›ç­”ã«å«ã‚ã‚‹ã¹ãæƒ…å ±ï¼ˆä»•æ§˜æ›¸ã«ã‚ã‚‹å ´åˆï¼‰
- è£½å“åã¨å‹ç•ª
- ä¸»è¦ã‚¹ãƒšãƒƒã‚¯ï¼ˆã‚µã‚¤ã‚ºã€é‡é‡ã€ç´ æãªã©ï¼‰
- ä¸»ãªæ©Ÿèƒ½ãƒ»ç‰¹å¾´
- ä½¿ç”¨ã‚·ãƒ¼ãƒ³ãƒ»æ¨å¥¨ç”¨é€”

## å¯¾å¿œã—ãªã„ç¯„å›²ï¼ˆsql_agentã«ä»»ã›ã‚‹ï¼‰
- ã€Œã“ã®è£½å“ã®å£²ä¸Šã¯ï¼Ÿã€â†’ sql_agent
- ã€Œä¸€ç•ªå£²ã‚Œã¦ã„ã‚‹è£½å“ã¯ï¼Ÿã€â†’ sql_agent
- ã€Œé¡§å®¢ã®è³¼å…¥å±¥æ­´ã€â†’ sql_agent

## æ³¨æ„
- æ¤œç´¢ã¯1å›ã§ååˆ†ã§ã™ã€‚åŒã˜å†…å®¹ã‚’è¤‡æ•°å›æ¤œç´¢ã—ãªã„ã§ãã ã•ã„
- æ¤œç´¢çµæœãŒãªã„å ´åˆã¯ã€Œè©²å½“ã™ã‚‹è£½å“ä»•æ§˜æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€ã¨å ±å‘Š
- ä»•æ§˜æ›¸ã®å†…å®¹ã‚’å¼•ç”¨ã™ã‚‹éš›ã¯å‡ºå…¸ã‚’æ˜è¨˜
""",
        chat_client=chat_client,
        tools=[search_documents],
    )

    return sql_agent, web_agent, doc_agent


def create_manager_agent(chat_client: AzureOpenAIChatClient) -> ChatAgent:
    """Create the manager agent for MagenticBuilder orchestration.

    Manager Agent ã®å½¹å‰²:
    1. è¤‡é›‘ãªã‚¯ã‚¨ãƒªã‚’ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã«åˆ†è§£ï¼ˆPlanï¼‰
    2. å„ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆã¸ã®ã‚¿ã‚¹ã‚¯å‰²ã‚Šå½“ã¦
    3. é€²æ—ã®ç›£è¦–ã¨å¿…è¦ã«å¿œã˜ãŸå†è¨ˆç”»
    4. å…¨ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆã®çµæœã‚’çµ±åˆã—ã¦æœ€çµ‚å›ç­”ã‚’ç”Ÿæˆ

    Args:
        chat_client: The AzureOpenAIChatClient to use.

    Returns:
        Manager ChatAgent
    """
    return ChatAgent(
        name="MagenticManager",
        description="ãƒãƒ¼ãƒ ã‚’èª¿æ•´ã—ã¦è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã‚’åŠ¹ç‡çš„ã«å®Œäº†ã•ã›ã‚‹ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼",
        instructions="""ã‚ãªãŸã¯Magentic Oneã®ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚
ãƒãƒ¼ãƒ ã‚’èª¿æ•´ã—ã¦è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã‚’åŠ¹ç‡çš„ã«å®Œäº†ã•ã›ã¾ã™ã€‚

## ã‚ãªãŸã®ãƒãƒ¼ãƒ 
| ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ | å½¹å‰² | å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ |
|-------------|------|----------|
| sql_agent | ã€æœ€å„ªå…ˆã€‘ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿åˆ†æ | å£²ä¸Šã€æ³¨æ–‡ã€é¡§å®¢ã€è£½å“ï¼ˆFabric SQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼‰ |
| web_agent | å¤–éƒ¨æƒ…å ±æ¤œç´¢ | æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€å¸‚å ´ãƒˆãƒ¬ãƒ³ãƒ‰ã€æ¥­ç•Œå‹•å‘ |
| doc_agent | è£½å“ä»•æ§˜æ›¸æ¤œç´¢ | ãƒãƒƒã‚¯ãƒ‘ãƒƒã‚¯ã€è‡ªè»¢è»Šã€ãƒ˜ãƒ«ãƒ¡ãƒƒãƒˆã€ãƒ†ãƒ³ãƒˆç­‰ã®PDF |
| ã‚ãªãŸè‡ªèº« | ä¸€èˆ¬çŸ¥è­˜ | æ¦‚å¿µèª¬æ˜ã€ç”¨èªè§£èª¬ã€ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ |

## ã‚¯ã‚¨ãƒªè§£æãƒ•ãƒ­ãƒ¼

### ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ã‚’ç†è§£
1. **ä½•ã‚’çŸ¥ã‚ŠãŸã„ã‹** - æ•°å€¤ã€æƒ…å ±ã€æ‰‹é †ã€æ¦‚å¿µèª¬æ˜ãªã©
2. **ã©ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã‹** - å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã€å¤–éƒ¨æƒ…å ±ã€ç¤¾å†…æ–‡æ›¸ã€ä¸€èˆ¬çŸ¥è­˜ãªã©
3. **ã©ã†è¡¨ç¤ºã—ãŸã„ã‹** - ãƒ†ã‚­ã‚¹ãƒˆã€è¡¨ã€ã‚°ãƒ©ãƒ•ãªã©

### ã‚¹ãƒ†ãƒƒãƒ—2: é©åˆ‡ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé¸æŠ

#### sql_agent ã‚’ä½¿ã†å ´åˆï¼ˆãƒ‡ãƒ¼ã‚¿åˆ†æå…¨èˆ¬ - æœ€å„ªå…ˆï¼‰
- æ•°å€¤ç³»: ã€Œå£²ä¸Šã€ã€Œæ³¨æ–‡ã€ã€Œé¡§å®¢ã€ã€Œè£½å“ã€ã€Œé‡‘é¡ã€ã€Œæ•°é‡ã€ã€Œä»¶æ•°ã€
- é›†è¨ˆç³»: ã€Œåˆè¨ˆã€ã€Œå¹³å‡ã€ã€Œæœ€å¤§ã€ã€Œæœ€å°ã€ã€Œä¸€ç•ªã€ã€ŒTOPã€ã€Œãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€
- æ¯”è¼ƒç³»: ã€Œæ¯”è¼ƒã€ã€Œå‰æœˆæ¯”ã€ã€Œå‰å¹´æ¯”ã€ã€Œæˆé•·ã€ã€Œæ¨ç§»ã€ã€Œãƒˆãƒ¬ãƒ³ãƒ‰ã€
- åˆ†æç³»: ã€Œå†…è¨³ã€ã€Œæ§‹æˆæ¯”ã€ã€Œå‰²åˆã€ã€Œåˆ†å¸ƒã€
- å¯è¦–åŒ–: ã€Œã‚°ãƒ©ãƒ•ã€ã€Œãƒãƒ£ãƒ¼ãƒˆã€ã€Œæ£’ã‚°ãƒ©ãƒ•ã€ã€Œå††ã‚°ãƒ©ãƒ•ã€ã€ŒæŠ˜ã‚Œç·šã€ã€Œè¡¨ç¤ºã—ã¦ã€

#### web_agent ã‚’ä½¿ã†å ´åˆ
- ã€Œæœ€æ–°ã€ã€Œãƒ‹ãƒ¥ãƒ¼ã‚¹ã€ã€Œãƒˆãƒ¬ãƒ³ãƒ‰ã€ã€Œå¸‚å ´å‹•å‘ã€ã€Œæ¥­ç•Œã€ã€Œç«¶åˆã€
- ã€Œå¤–éƒ¨ã€ã€Œã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã€ã€Œ2025å¹´ã€ã€Œ2026å¹´ã€ï¼ˆæœ€æ–°æƒ…å ±ï¼‰

#### doc_agent ã‚’ä½¿ã†å ´åˆ
- ã€Œä»•æ§˜ã€ã€Œã‚¹ãƒšãƒƒã‚¯ã€ã€Œæ©Ÿèƒ½ã€ã€Œç´ æã€ã€Œé‡é‡ã€ã€Œã‚µã‚¤ã‚ºã€ã€Œå®¹é‡ã€
- è£½å“å: ã€ŒMountain-100ã€ã€ŒSport-100 Helmetã€ã€ŒAlpine Explorerã€
- ã‚«ãƒ†ã‚´ãƒª: ã€Œãƒãƒƒã‚¯ãƒ‘ãƒƒã‚¯ã€ã€Œãƒ†ãƒ³ãƒˆã€ã€Œãƒ˜ãƒ«ãƒ¡ãƒƒãƒˆã€ã€Œã‚³ãƒ¼ãƒ’ãƒ¼ãƒ¡ãƒ¼ã‚«ãƒ¼ã€

#### ã‚ãªãŸè‡ªèº«ã®çŸ¥è­˜ã‚’ä½¿ã†å ´åˆï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä¸è¦ï¼‰
- ã€Œã¨ã¯ã€ã€Œæ„å‘³ã€ã€Œèª¬æ˜ã€ã€Œå®šç¾©ã€ã€Œã©ã†ã‚„ã£ã¦ã€ã€Œæ–¹æ³•ã€
- æ¦‚å¿µèª¬æ˜: ã€ŒKPIã¨ã¯ã€ã€ŒROIã®è¨ˆç®—æ–¹æ³•ã€ã€ŒRFMåˆ†æã¨ã¯ã€
- ä¸€èˆ¬çš„ãªãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚„ã‚¢ãƒ‰ãƒã‚¤ã‚¹
- æŒ¨æ‹¶: ã€Œã“ã‚“ã«ã¡ã¯ã€ã€Œã‚ã‚ŠãŒã¨ã†ã€

### ã‚¹ãƒ†ãƒƒãƒ—3: è¤‡åˆã‚¯ã‚¨ãƒªã®å‡¦ç†

**ãƒ‘ã‚¿ãƒ¼ãƒ³1: ãƒ‡ãƒ¼ã‚¿ + èª¬æ˜**
ä¾‹: ã€Œå£²ä¸ŠTOP5ã‚’åˆ†æã—ã¦å‚¾å‘ã‚’èª¬æ˜ã€
â†’ sql_agent ã§å£²ä¸Šå–å¾— â†’ ã‚ãªãŸã®çŸ¥è­˜ã§å‚¾å‘åˆ†æã‚’è¿½åŠ 

**ãƒ‘ã‚¿ãƒ¼ãƒ³2: ãƒ‡ãƒ¼ã‚¿ + å¤–éƒ¨æƒ…å ±**
ä¾‹: ã€Œè‡ªç¤¾å£²ä¸Šã‚’å¸‚å ´å‹•å‘ã¨æ¯”è¼ƒã€
â†’ sql_agent ã§å£²ä¸Šå–å¾— â†’ web_agent ã§å¸‚å ´æƒ…å ±å–å¾— â†’ çµ±åˆ

**ãƒ‘ã‚¿ãƒ¼ãƒ³3: è£½å“æƒ…å ± + ãƒ‡ãƒ¼ã‚¿**
ä¾‹: ã€ŒMountain-100ã®ä»•æ§˜ã¨å£²ä¸Šã‚’æ•™ãˆã¦ã€
â†’ doc_agent ã§ä»•æ§˜å–å¾— â†’ sql_agent ã§å£²ä¸Šå–å¾— â†’ çµ±åˆ

**ãƒ‘ã‚¿ãƒ¼ãƒ³4: æ¦‚å¿µèª¬æ˜ + å®Ÿãƒ‡ãƒ¼ã‚¿**
ä¾‹: ã€ŒRFMåˆ†æã¨ã¯ä½•ã‹ã€é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã«é©ç”¨ã€
â†’ ã‚ãªãŸã®çŸ¥è­˜ã§RFMèª¬æ˜ â†’ sql_agent ã§é¡§å®¢åˆ†æ â†’ çµ±åˆ

### ã‚¹ãƒ†ãƒƒãƒ—4: å›ç­”ã®çµ±åˆ
1. å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çµæœã‚’è«–ç†çš„ã«æ•´ç†
2. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç›´æ¥ç­”ãˆã‚‹å½¢å¼ã§æ§‹æˆ
3. ãƒ‡ãƒ¼ã‚¿ã¨èª¬æ˜ã‚’çµ„ã¿åˆã‚ã›ã¦åˆ†ã‹ã‚Šã‚„ã™ãæç¤º

## ã‚°ãƒ©ãƒ•å‡ºåŠ›ãƒ«ãƒ¼ãƒ«ï¼ˆé‡è¤‡ç¦æ­¢ï¼‰

- sql_agentãŒã‚°ãƒ©ãƒ•ï¼ˆ```jsonï¼‰ã‚’å«ã‚€å›ç­”ã‚’è¿”ã—ãŸå ´åˆ â†’ **ãã®ã¾ã¾ä½¿ç”¨ã€‚è¿½åŠ ã®ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆã—ãªã„**
- sql_agentãŒã‚°ãƒ©ãƒ•ãªã—ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚°ãƒ©ãƒ•ã‚’è¦æ±‚ â†’ ã‚ãªãŸãŒChart.js JSONã‚’1ã¤ã ã‘è¿½åŠ 
- **çµ¶å¯¾ç¦æ­¢**: åŒã˜ã‚°ãƒ©ãƒ•ã‚’2å›å‡ºåŠ›ã€sql_agentã®ã‚°ãƒ©ãƒ•ã«åŠ ãˆã¦åˆ¥ã®ã‚°ãƒ©ãƒ•ã‚’è¿½åŠ 

## å‡¦ç†ãƒ«ãƒ¼ãƒ«
1. **åŠ¹ç‡å„ªå…ˆ**: å¿…è¦ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã¿å‘¼ã³å‡ºã™
2. **1ãƒ©ã‚¦ãƒ³ãƒ‰å®Œçµ**: å¯èƒ½ãªé™ã‚Š1å›ã§å®Œäº†
3. **æ—¥æœ¬èªã§å›ç­”**: è‡ªç„¶ã§åˆ†ã‹ã‚Šã‚„ã™ã
4. **çµæœçµ±åˆ**: è¤‡æ•°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çµæœã¯è«–ç†çš„ã«çµ±åˆ

## å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
- Markdownå½¢å¼ã§æ§‹é€ åŒ–
- é‡è¦ãªæ•°å€¤ã¯**å¼·èª¿**
- é•·ã„å›ç­”ã¯è¦‹å‡ºã—ã§åŒºåˆ‡ã‚‹
- ã‚°ãƒ©ãƒ•ã¯Chart.js JSONå½¢å¼ï¼ˆVega-Liteç¦æ­¢ï¼‰
""",
        chat_client=chat_client,
    )


async def stream_multi_agent_response(
    conversation_id: str, query: str, user_id: str = "anonymous"
):
    """
    Stream response using MagenticBuilder pattern for true multi-agent collaboration.

    MagenticBuilder (Magentic One Pattern):
    - Manager Agent ãŒã‚¿ã‚¹ã‚¯ã‚’åˆ†è§£ã—ã€è¨ˆç”»ã‚’ä½œæˆ
    - è¤‡æ•°ã®ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆãŒä¸¦åˆ—ã¾ãŸã¯é †æ¬¡å®Ÿè¡Œ
    - Manager ãŒçµæœã‚’çµ±åˆã—ã¦æœ€çµ‚å›ç­”ã‚’ç”Ÿæˆ

    ã“ã‚Œã«ã‚ˆã‚Šã€è¤‡åˆçš„ãªã‚¯ã‚¨ãƒªï¼ˆä¾‹ï¼šã€Œå£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦ã€æœ€æ–°ãƒˆãƒ¬ãƒ³ãƒ‰ã¨æ¯”è¼ƒã€ï¼‰ã«å¯¾å¿œå¯èƒ½ã€‚
    """
    try:
        # Get conversation history for multi-turn support (with timeout)
        history_messages = []
        try:
            import asyncio

            # Set a short timeout (3 seconds) to avoid blocking
            messages = await asyncio.wait_for(
                get_conversation_messages(user_id, conversation_id), timeout=3.0
            )
            if messages:
                # Convert to format suitable for agent (last N messages for context)
                # Limit to last 6 messages to reduce token usage
                recent_messages = messages[-6:] if len(messages) > 6 else messages
                for msg in recent_messages:
                    role = msg.get("role", "user")
                    content = msg.get("content", "")
                    if isinstance(content, str) and content:
                        history_messages.append({"role": role, "content": content})
                logger.info(
                    f"Loaded {len(history_messages)} messages from conversation history"
                )
        except asyncio.TimeoutError:
            logger.warning(
                "Conversation history fetch timed out, continuing without history"
            )
        except Exception as e:
            logger.warning(f"Could not load conversation history: {e}")
            # Continue without history

        # Use sync credential - SDK requires synchronous token acquisition
        credential = DefaultAzureCredential()

        # Get Azure OpenAI configuration from environment variables
        # SDK 1.0.0b260130 requires explicit deployment_name and endpoint
        deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_MODEL") or os.getenv(
            "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME"
        )
        endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
        api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-12-01-preview")

        logger.info(
            f"Azure OpenAI config: deployment={deployment_name}, endpoint={endpoint}"
        )

        if not deployment_name:
            raise ValueError(
                "Azure OpenAI deployment name is required. "
                "Set AZURE_OPENAI_DEPLOYMENT_MODEL or AZURE_OPENAI_CHAT_DEPLOYMENT_NAME"
            )
        if not endpoint:
            raise ValueError(
                "Azure OpenAI endpoint is required. Set AZURE_OPENAI_ENDPOINT"
            )

        # Create chat client with explicit configuration
        chat_client = AzureOpenAIChatClient(
            credential=credential,
            deployment_name=deployment_name,
            endpoint=endpoint,
            api_version=api_version,
        )

        # Create specialist agents
        sql_agent, web_agent, doc_agent = create_specialist_agents(chat_client)

        # Create manager agent
        manager_agent = create_manager_agent(chat_client)

        # Build the MagenticBuilder workflow
        # Note: App Serviceã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ230ç§’ï¼‰ã‚’è¶…ãˆãªã„ã‚ˆã†åˆ¶é™
        # è¤‡é›‘ãªã‚¯ã‚¨ãƒªã§ã‚‚1-2ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Œäº†ã™ã‚‹ã‚ˆã†è¨­è¨ˆ
        workflow = (
            MagenticBuilder()
            .participants([sql_agent, web_agent, doc_agent])
            .with_manager(
                agent=manager_agent,
                max_round_count=2,  # 504ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆé˜²æ­¢: 2ãƒ©ã‚¦ãƒ³ãƒ‰ä»¥å†…ã§å®Œäº†
                max_stall_count=1,  # åœæ»ã—ãŸã‚‰å³çµ‚äº†
            )
            .build()
        )

        logger.info(f"Starting MagenticBuilder workflow with query: {query[:100]}...")
        logger.info("Workflow configured with Manager + 3 Specialists (SQL, Web, Doc)")

        # Build the full prompt with conversation history
        if history_messages:
            # Format history as context for the agent
            history_context = "\n".join(
                [f"{msg['role'].upper()}: {msg['content']}" for msg in history_messages]
            )
            full_query = f"""## ä¼šè©±å±¥æ­´ï¼ˆå‚è€ƒã«ã—ã¦ãã ã•ã„ï¼‰
{history_context}

## ç¾åœ¨ã®è³ªå•
{query}"""
            logger.info(f"Including {len(history_messages)} messages in context")
        else:
            full_query = query

        last_message_id: str | None = None
        last_executor_id: str | None = None
        specialist_outputs: dict[str, str] = {}  # Specialiståˆ¥ã®å‡ºåŠ›ã‚’è“„ç©
        manager_output = ""  # Managerã®æœ€çµ‚å‡ºåŠ›
        is_manager_streaming = False  # ManagerãŒã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ä¸­ã‹ã©ã†ã‹

        # Stream the workflow execution
        # æˆ¦ç•¥: Specialistã®å‡ºåŠ›ã¯è“„ç©ã®ã¿ã€Managerã®æœ€çµ‚å¿œç­”ã®ã¿ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒ 
        # ã“ã‚Œã«ã‚ˆã‚Šå¿œç­”ã‚µã‚¤ã‚ºã‚’å‰Šæ¸›ã—ã¤ã¤ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¯ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ä½“é¨“ã‚’æä¾›

        async for event in workflow.run_stream(full_query):
            if isinstance(event, AgentRunUpdateEvent):
                update = event.data
                message_id = getattr(update, "message_id", None)
                executor_id = str(getattr(event, "executor_id", "unknown"))
                text_chunk = ""

                if hasattr(update, "text") and update.text:
                    text_chunk = update.text
                elif isinstance(update, str):
                    text_chunk = update

                if not text_chunk:
                    continue

                # executor_idã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è­˜åˆ¥
                # MagenticManager ã¾ãŸã¯ Manager ã‚’å«ã‚€å ´åˆã¯Manager
                is_manager = (
                    "manager" in executor_id.lower()
                    or "magentic" in executor_id.lower()
                )

                # æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆ
                if message_id and message_id != last_message_id:
                    if last_executor_id:
                        logger.info(f"Agent {last_executor_id} completed response")
                    last_message_id = message_id
                    last_executor_id = executor_id

                    # Managerã®æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå§‹ã¾ã£ãŸ
                    if is_manager:
                        is_manager_streaming = True
                        logger.info(f"Manager streaming started: {executor_id}")

                if is_manager:
                    # Managerã®å‡ºåŠ›ã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã‚¹ãƒˆãƒªãƒ¼ãƒ 
                    manager_output += text_chunk
                    yield text_chunk
                else:
                    # Specialistã®å‡ºåŠ›ã¯è“„ç©ã®ã¿ï¼ˆãƒ­ã‚°ã«è¨˜éŒ²ï¼‰
                    if executor_id not in specialist_outputs:
                        specialist_outputs[executor_id] = ""
                    specialist_outputs[executor_id] += text_chunk

            elif isinstance(event, MagenticOrchestratorEvent):
                logger.info(f"Orchestrator event: {type(event).__name__}")
                plan = getattr(event, "plan", None)
                if plan:
                    logger.info(f"Plan created: {plan}")

            elif isinstance(event, WorkflowOutputEvent):
                # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº†æ™‚ã®æœ€çµ‚å‡ºåŠ›
                logger.info("WorkflowOutputEvent received")
                if event.data:
                    output_messages = event.data
                    final_text = ""
                    if isinstance(output_messages, list):
                        for msg in output_messages:
                            if hasattr(msg, "text") and msg.text:
                                final_text = msg.text
                    elif isinstance(output_messages, str):
                        final_text = output_messages

                    # ã¾ã ã‚¹ãƒˆãƒªãƒ¼ãƒ ã•ã‚Œã¦ã„ãªã„éƒ¨åˆ†ãŒã‚ã‚Œã°yield
                    if final_text and final_text != manager_output:
                        remaining = (
                            final_text[len(manager_output) :]
                            if final_text.startswith(manager_output)
                            else final_text
                        )
                        if remaining:
                            logger.info(
                                f"Yielding remaining final output: {len(remaining)} chars"
                            )
                            yield remaining
                            manager_output = final_text

                logger.info("MagenticBuilder workflow completed")

            elif isinstance(event, WorkflowStatusEvent):
                state_name = (
                    str(event.state.name)
                    if hasattr(event.state, "name")
                    else str(event.state)
                )
                logger.info(f"Workflow status: {state_name}")

            elif isinstance(event, GroupChatRequestSentEvent):
                logger.info(f"Request sent to: {getattr(event, 'target', 'unknown')}")

            elif isinstance(event, RequestInfoEvent):
                logger.info(f"Request info event: {event}")

        # ãƒ­ã‚°ã«Specialistå‡ºåŠ›ã®ã‚µãƒãƒªãƒ¼ã‚’è¨˜éŒ²
        for agent_id, output in specialist_outputs.items():
            logger.info(f"Specialist {agent_id} output: {len(output)} chars")

        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãŒå…¨ããªã‹ã£ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if not manager_output:
            logger.warning(
                "No manager output streamed, using accumulated specialist outputs"
            )
            # Specialistã®å‡ºåŠ›ã‚’çµåˆã—ã¦è¿”ã™
            combined = "\n\n".join(
                f"### {agent_id}\n{output}"
                for agent_id, output in specialist_outputs.items()
                if output
            )
            if combined:
                yield combined

    except Exception as e:
        logger.error(f"Error in MagenticBuilder workflow: {e}", exc_info=True)
        raise
    finally:
        global _db_connection
        if _db_connection:
            try:
                _db_connection.close()
            except Exception:
                pass
            _db_connection = None


async def stream_single_agent_response(conversation_id: str, query: str):
    """
    Stream response using single agent mode with AzureOpenAIChatClient.
    """
    try:
        # Use sync credential - SDK requires synchronous token acquisition
        credential = DefaultAzureCredential()

        # Get Azure OpenAI configuration from environment variables
        # SDK 1.0.0b260130 requires explicit deployment_name and endpoint
        deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_MODEL") or os.getenv(
            "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME"
        )
        endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
        api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-12-01-preview")

        logger.info(
            f"Azure OpenAI config: deployment={deployment_name}, endpoint={endpoint}"
        )

        if not deployment_name:
            raise ValueError(
                "Azure OpenAI deployment name is required. "
                "Set AZURE_OPENAI_DEPLOYMENT_MODEL or AZURE_OPENAI_CHAT_DEPLOYMENT_NAME"
            )
        if not endpoint:
            raise ValueError(
                "Azure OpenAI endpoint is required. Set AZURE_OPENAI_ENDPOINT"
            )

        # Create chat client with explicit configuration
        chat_client = AzureOpenAIChatClient(
            credential=credential,
            deployment_name=deployment_name,
            endpoint=endpoint,
            api_version=api_version,
        )

        # Create a single agent with SQL tool
        agent = chat_client.as_agent(
            name="data_analyst",
            instructions="""ã‚ãªãŸã¯Fabric SQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ã£ã¦ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

## åˆ©ç”¨å¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆå®Ÿéš›ã®ã‚¹ã‚­ãƒ¼ãƒï¼‰
- orders: æ³¨æ–‡ãƒ˜ãƒƒãƒ€ãƒ¼ (OrderId, CustomerId, OrderDate, OrderStatus, OrderTotal, PaymentMethod)
- orderline: æ³¨æ–‡æ˜ç´° (OrderId, ProductId, Quantity, UnitPrice, LineTotal)
- product: è£½å“ (ProductID, ProductName, CategoryName, ListPrice, BrandName, Color, ProductCategoryID)
- productcategory: ã‚«ãƒ†ã‚´ãƒª (CategoryID, CategoryName, ParentCategoryId)
- customer: é¡§å®¢ (CustomerId, FirstName, LastName, CustomerTypeId, CustomerRelationshipTypeId)
- customerrelationshiptype: é¡§å®¢ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ (CustomerRelationshipTypeId, CustomerRelationshipTypeName)
- location: æ‰€åœ¨åœ° (LocationId, CustomerId, Region, City, StateId)
- invoice: è«‹æ±‚æ›¸ (InvoiceId, CustomerId, OrderId, TotalAmount, InvoiceStatus)
- payment: æ”¯æ‰•ã„ (PaymentId, InvoiceId, PaymentAmount, PaymentStatus, PaymentMethod)

## ä¸»è¦ãªJOINãƒ‘ã‚¿ãƒ¼ãƒ³
- å£²ä¸Šåˆ†æ: orders JOIN orderline ON OrderId JOIN product ON ProductId
- é¡§å®¢åˆ†æ: orders JOIN customer ON CustomerId
- åœ°åŸŸåˆ†æ: customer JOIN location ON CustomerId
- ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æ: customer JOIN customerrelationshiptype ON CustomerRelationshipTypeId

## ã‚¿ã‚¹ã‚¯
1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’åˆ†æ
2. å¿…è¦ã«å¿œã˜ã¦run_sql_queryãƒ„ãƒ¼ãƒ«ã§ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
3. çµæœã‚’åˆ†ã‹ã‚Šã‚„ã™ãæ•´å½¢ã—ã¦å›ç­”

## å›ç­”å½¢å¼
- ãƒ‡ãƒ¼ã‚¿ã¯è¡¨å½¢å¼ã§è¦‹ã‚„ã™ãè¡¨ç¤º
- Chart.js JSONã¯ã‚°ãƒ©ãƒ•ãŒé©åˆ‡ãªå ´åˆã«å«ã‚ã‚‹ï¼ˆVega-Liteç¦æ­¢ï¼‰
""",
            tools=[run_sql_query],
        )

        logger.info(f"Single agent mode: processing query: {query[:100]}...")

        # Stream the agent response
        async for chunk in agent.run_stream(query):
            if chunk and chunk.text:
                yield chunk.text

    except Exception as e:
        logger.error(f"Error in single agent response: {e}", exc_info=True)
        raise
    finally:
        global _db_connection
        if _db_connection:
            try:
                _db_connection.close()
            except Exception:
                pass
            _db_connection = None


# ============================================================================
# Chat API Endpoint
# ============================================================================


def requires_multi_agent(query: str) -> bool:
    """
    ã‚¯ã‚¨ãƒªã®è¤‡é›‘ã•ã‚’åˆ¤å®šã—ã€ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå¿…è¦ã‹ã©ã†ã‹ã‚’è¿”ã™ã€‚
    
    ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå¿…è¦ãªã‚±ãƒ¼ã‚¹:
    - è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãŒå¿…è¦ï¼ˆå£²ä¸Š+ä»•æ§˜ã€ãƒ‡ãƒ¼ã‚¿+å¸‚å ´ãƒˆãƒ¬ãƒ³ãƒ‰ç­‰ï¼‰
    - æ˜ç¤ºçš„ã«è¤‡åˆåˆ†æã‚’è¦æ±‚
    
    ã‚·ãƒ³ã‚°ãƒ«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ååˆ†ãªã‚±ãƒ¼ã‚¹:
    - å˜ç´”ãªå£²ä¸Šãƒ»æ³¨æ–‡ã‚¯ã‚¨ãƒª
    - æŒ¨æ‹¶ãƒ»é›‘è«‡
    - æ¦‚å¿µèª¬æ˜ã®ã¿
    """
    query_lower = query.lower()
    
    # è¤‡åˆã‚¯ã‚¨ãƒªã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¿…è¦ï¼‰
    multi_agent_keywords = [
        # è¤‡æ•°ã‚½ãƒ¼ã‚¹è¦æ±‚
        "ä»•æ§˜ã¨å£²ä¸Š", "å£²ä¸Šã¨ä»•æ§˜", "ã‚¹ãƒšãƒƒã‚¯ã¨å£²ä¸Š", "å£²ä¸Šã¨ã‚¹ãƒšãƒƒã‚¯",
        "å¸‚å ´ã¨å£²ä¸Š", "å£²ä¸Šã¨å¸‚å ´", "ãƒˆãƒ¬ãƒ³ãƒ‰ã¨å£²ä¸Š", "å£²ä¸Šã¨ãƒˆãƒ¬ãƒ³ãƒ‰",
        "æ¯”è¼ƒã—ã¦", "ã¨æ¯”è¼ƒ", "åˆã‚ã›ã¦", "ä½µã›ã¦",
        # å¤–éƒ¨æƒ…å ±+å†…éƒ¨ãƒ‡ãƒ¼ã‚¿
        "æœ€æ–°ã®", "2026å¹´", "2025å¹´", "ãƒ‹ãƒ¥ãƒ¼ã‚¹", "å¸‚å ´å‹•å‘",
        # è£½å“ä»•æ§˜æ¤œç´¢
        "ä»•æ§˜", "ã‚¹ãƒšãƒƒã‚¯", "ç´ æ", "æ©Ÿèƒ½", "ç‰¹å¾´ã¯",
    ]
    
    # ã‚·ãƒ³ã‚°ãƒ«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ååˆ†ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    single_agent_keywords = [
        # æŒ¨æ‹¶ãƒ»é›‘è«‡
        "ã“ã‚“ã«ã¡ã¯", "ã‚ã‚ŠãŒã¨ã†", "ã‚ˆã‚ã—ã", "hello", "hi",
        # å˜ç´”ãªãƒ‡ãƒ¼ã‚¿ã‚¯ã‚¨ãƒª
        "å£²ä¸Štop", "å£²ä¸Šãƒ©ãƒ³ã‚­ãƒ³ã‚°", "ä¸€è¦§", "ãƒªã‚¹ãƒˆ",
        "ä½•ä»¶", "ã„ãã¤", "ç·æ•°", "åˆè¨ˆ",
    ]
    
    # æŒ¨æ‹¶ã‚„å˜ç´”ã‚¯ã‚¨ãƒªã¯å³åº§ã«ã‚·ãƒ³ã‚°ãƒ«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    for kw in single_agent_keywords:
        if kw in query_lower:
            return False
    
    # è¤‡åˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚Œã°ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    for kw in multi_agent_keywords:
        if kw in query_lower:
            return True
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã‚·ãƒ³ã‚°ãƒ«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆé«˜é€Ÿï¼‰
    return False


async def stream_chat_request(
    conversation_id: str, query: str, user_id: str = "anonymous"
):
    """
    Handles streaming chat requests.

    Routes to:
    - Multi-agent mode: Uses MagenticBuilder with Manager + Specialist agents
    - Single-agent mode: Direct ChatAgent with SQL tools
    """

    async def generate():
        try:
            assistant_content = ""

            # ã‚¯ã‚¨ãƒªã®è¤‡é›‘ã•ã«å¿œã˜ã¦ãƒ¢ãƒ¼ãƒ‰ã‚’å‹•çš„ã«é¸æŠ
            use_multi_agent = MULTI_AGENT_MODE and requires_multi_agent(query)
            
            if use_multi_agent:
                logger.info(f"Using multi-agent mode for complex query: {query[:50]}...")
                stream_func = lambda cid, q: stream_multi_agent_response(
                    cid, q, user_id
                )
            else:
                logger.info(f"Using single-agent mode for query: {query[:50]}...")
                stream_func = stream_single_agent_response

            # Stream and accumulate response
            async for chunk in stream_func(conversation_id, query):
                if chunk:
                    assistant_content += str(chunk)
                    response = {
                        "choices": [
                            {
                                "messages": [
                                    {
                                        "role": "assistant",
                                        "content": assistant_content,
                                    }
                                ]
                            }
                        ]
                    }
                    yield json.dumps(response, ensure_ascii=False) + "\n\n"

            # Fallback if no response
            if not assistant_content:
                logger.info("No response received")
                response = {
                    "choices": [
                        {
                            "messages": [
                                {
                                    "role": "assistant",
                                    "content": "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ã“ã®è³ªå•ã«ã¯ãŠç­”ãˆã§ãã¾ã›ã‚“ã€‚è³ªå•ã‚’å¤‰ãˆã¦ãŠè©¦ã—ãã ã•ã„ã€‚",
                                }
                            ]
                        }
                    ]
                }
                yield json.dumps(response, ensure_ascii=False) + "\n\n"

        except Exception as e:
            error_message = str(e)
            if "Rate limit" in error_message:
                match = re.search(r"Try again in (\d+) seconds.", error_message)
                retry_after = match.group(1) if match else "sometime"
                logger.error(f"Rate limit error: {error_message}")
                yield (
                    json.dumps(
                        {
                            "error": f"Rate limit is exceeded. Try again in {retry_after} seconds."
                        }
                    )
                    + "\n\n"
                )
            else:
                logger.error(f"Unexpected error: {e}", exc_info=True)
                yield (
                    json.dumps(
                        {"error": "An error occurred while processing the request."}
                    )
                    + "\n\n"
                )

    return generate()


@router.post("/chat")
async def conversation(request: Request):
    """Handle chat requests - streaming text or chart generation based on query keywords."""
    try:
        request_json = await request.json()
        conversation_id = request_json.get("conversation_id")
        query = request_json.get("query")
        # Get user_id from request or use anonymous
        user_id = request_json.get("user_id", "anonymous")

        if not query:
            return JSONResponse(content={"error": "Query is required"}, status_code=400)

        if not conversation_id:
            return JSONResponse(
                content={"error": "Conversation ID is required"}, status_code=400
            )

        result = await stream_chat_request(conversation_id, query, user_id)
        track_event_if_configured(
            "ChatStreamSuccess", {"conversation_id": conversation_id, "query": query}
        )
        return StreamingResponse(result, media_type="application/json-lines")

    except Exception as ex:
        logger.exception(f"Error in conversation endpoint: {str(ex)}")
        span = trace.get_current_span()
        if span is not None:
            span.record_exception(ex)
            span.set_status(Status(StatusCode.ERROR, str(ex)))
        return JSONResponse(
            content={
                "error": "An internal error occurred while processing the conversation."
            },
            status_code=500,
        )
